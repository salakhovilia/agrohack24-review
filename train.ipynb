{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2457847-75a5-4e15-9395-5ba4c36ccd53",
   "metadata": {},
   "source": [
    "### **AgroHack - soybeans yield prediction**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Постановка задачи**\n",
    "Наша цель — спрогнозировать урожайность сои, используя ее генотипические данные и данные о погодных условиях в регионе высаживания. Для этого мы разработали подход, который позволяет перевести биологические последовательности (нуклеотидный набор, представляющий собой их последовательность с учетом мутаций) в числовые представления, а затем применить машинное обучение для создания предсказательной модели. Этот ноутбук посвящен работе с био фичами и последующим обучением модели вместе с погодой.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Методы построения фичей**\n",
    "Для перевода биологических данных в цифровую форму мы использовали несколько ключевых этапов:\n",
    "\n",
    "1. **Сбор и обработка генотипических данных**:\n",
    "   - Данные представлены в формате VCF, содержащем информацию о референсных и альтернативных аллелях для каждой позиции генома.\n",
    "   - Мы упорядочили данные по хромосоме и позиции, обработали пропуски, чтобы сохранить целостность последовательностей.\n",
    "\n",
    "2. **Цифровизация последовательностей через `k-mers`**:\n",
    "   - Длинные нуклеотидные последовательности были разбиты на подстроки фиксированной длины \\( k=3 \\), так как триплет представляет собой одну аминокислоту.\n",
    "\n",
    "3. **Эмбеддинги с использованием Word2Vec**:\n",
    "   - `k-mers` были преобразованы в числовые векторы с использованием модели Word2Vec, которая извлекает контекстные зависимости между ними.\n",
    "   - Итоговое представление каждой последовательности — это усредненный вектор всех её `k-mers`. Это компактное числовое представление генотипов, готовое для использования в моделях машинного обучения.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Baseline**\n",
    "1. **Работа по его построению**:\n",
    "   - Каждый генотип представляет собой набор из ~40 тысяч фичей, обработка классическими моделями получилась вычислительно долгой и совершенно неоптимизированной\n",
    "   - Обработка данных о количестве мутаций для снижения числа фичей и как способ предсказания не дал положительных результатов - 98% дисперсии такая модель обьяснить не может\n",
    "   - Обработка данных о погоде (соседний ноутбук)\n",
    "   - Оценка качества на простых моделях (RandomForestRegressor)\n",
    "\n",
    "---\n",
    "#### **Методы анализа**\n",
    "1. **Модели машинного обучения**:\n",
    "   - Мы использовали CatBoostRegressor для построения модели, которая предсказывает урожайность на основе созданных эмбеддингов и погодных факторов.\n",
    "   - CatBoost, как градиентный бустинг, показал себя наиболее эффективно благодаря встроенной обработке числовых данных и оптимизации.\n",
    "   - Также, мы использовали библиотеку optuna для подбора наилучших гиперпараметров модели\n",
    "\n",
    "2. **Метрики оценки**:\n",
    "   - Для оценки точности модели мы применили метрики MSE (среднеквадратическая ошибка) и \\( R^2 \\) (коэффициент детерминации).\n",
    "   - Эти метрики помогли нам определить, насколько модель отражает реальные данные.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Итог**\n",
    "Мы продемонстрировали, как генетические данные могут быть цифровизированы и использованы для предсказания продуктивности растений. Этот подход:\n",
    "\n",
    "- Основан на биологических закономерностях, таких как структура `k-mers` в ДНК.\n",
    "- Применяет современные методы эмбеддингов для создания информативных фичей.\n",
    "- Использует мощные модели машинного обучения для получения точных прогнозов.\n",
    "- Качество модели: CatBoost Mean Squared Error (RMSE): **15.2**; CatBoost R^2 Score: **0.163**\n",
    "- Мы получили решение, с помощью которого в дальнейшем важность отдельных эмбеддингов можно интерпретировать как важность мутации конкретных генов и, отталкиваясь от этого, планировать селекцию и экспериментировать с получившимися генотипами\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb9f2f7-61c9-4a9d-881c-3132c60b8a18",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /opt/conda/lib/python3.11/site-packages (1.2.7)\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.11/site-packages (4.3.3)\n",
      "Collecting optuna\n",
      "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.11/site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (from catboost) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.11/site-packages (from catboost) (1.24.4)\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.11/site-packages (from catboost) (2.1.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from catboost) (1.11.3)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.11/site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.11/site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from optuna) (1.12.0)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from optuna) (23.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.11/site-packages (from optuna) (2.0.22)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from optuna) (4.66.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.11/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (4.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->catboost) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->catboost) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->catboost) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->catboost) (3.1.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from plotly->catboost) (9.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: colorlog, optuna\n",
      "Successfully installed colorlog-6.9.0 optuna-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost gensim optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4618fae-5ab4-4b3f-87d7-b13d928f146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "798dd11b-05b7-424c-bfd7-60f6aa5df392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_to_long(phenotypes_df:pd.DataFrame(),  value_vars:list, id_vars='sample') -> pd.DataFrame():\n",
    "    \"\"\"\n",
    "    Преобразует широкую таблицу с таргетами в длинную.\n",
    "    \n",
    "    :param df: Исходный DataFrame в широком формате.\n",
    "    :param id_vars: sample, которые остаются идентификаторами.\n",
    "    :param value_vars: Года, которые нужно преобразовать в длинный формат.\n",
    "    :return: DataFrame в длинном формате.\n",
    "    \"\"\"\n",
    "    if value_vars is None:\n",
    "        value_vars = ['2015', '2016', '2017', '2019', '2020', '2021', '2022', '2023']\n",
    "        \n",
    "    target_df = (pd.melt(phenotypes_df, id_vars=['sample'], value_vars=value_vars)\n",
    "             .dropna()\n",
    "             .rename(columns={'variable':'year',\n",
    "                              'value':'yield'}\n",
    "                    )\n",
    "            )\n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b77676a-309c-4ba4-8ed3-5db5bec456b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлекаем аллели\n",
    "def extract_allele(gt, ref, alt):\n",
    "    \"\"\"\n",
    "    Достаем аллель по типу мутации\n",
    "    \n",
    "    :param gt: мутация\n",
    "    :param ref: референсный аллель.\n",
    "    :param alt: альтернатиыный аллель\n",
    "    :return: нуклеотидная последовательность\n",
    "    \"\"\"\n",
    "    if gt == \"./.\":\n",
    "        return \"\" \n",
    "    alleles = gt.split(\":\")[0].split(\"/\") \n",
    "    seq = \"\".join([ref if a == \"0\" else alt if a != \"0\" else \"\" for a in alleles])\n",
    "    return seq\n",
    "\n",
    "# разбиение последовательности на k-mers\n",
    "def generate_kmers(sequence, k=3):\n",
    "    return [sequence[i:i+k] for i in range(len(sequence) - k + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52db1973-f0dc-49a3-b551-f5e4a0364062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vcf(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = [line.strip() for line in file if not line.startswith('##')]  # Пропускаем метаданные\n",
    "    headers = lines[0].split('\\t')  # Заголовки колонок\n",
    "    data = [line.split('\\t') for line in lines[1:]]  # Данные\n",
    "    vcf_df = pd.DataFrame(data, columns=headers)\n",
    "    return vcf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0426046-a27b-417a-a91f-5538fc219820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение файлов\n",
    "genotypes = read_vcf('genotypes.vcf')\n",
    "raw_phenotypes = pd.read_csv('phenotypes.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fac9d814-582a-4bac-ab62-8a13594ccafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлечение образцов и построение последовательностей\n",
    "sample_columns = genotypes.columns[9:]  # Колонки с образцами\n",
    "sample_sequences = {sample: [] for sample in sample_columns}\n",
    "\n",
    "genotypes[\"POS\"] = pd.to_numeric(genotypes[\"POS\"], errors=\"coerce\")\n",
    "genotypes.sort_values(by=[\"#CHROM\", \"POS\"], inplace=True)  # сортировка по хромосоме и позиции\n",
    "\n",
    "for _, row in genotypes.iterrows():\n",
    "    ref = row[\"REF\"]\n",
    "    alt = row[\"ALT\"]\n",
    "    for sample in sample_columns:\n",
    "        gt = row[sample]\n",
    "        allele_seq = extract_allele(gt, ref, alt)\n",
    "        sample_sequences[sample].append(allele_seq)\n",
    "\n",
    "# объединяем последовательности в строки\n",
    "sample_sequences = {sample: \"\".join(seq) for sample, seq in sample_sequences.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e16005d-0391-4aac-9659-bcc168e8d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# генерация k-mers и обучение Word2Vec\n",
    "k = 3  # Размер k-mers\n",
    "kmers_samples = {sample: generate_kmers(seq, k=k) for sample, seq in sample_sequences.items()}\n",
    "sentences = list(kmers_samples.values())\n",
    "\n",
    "# обучение модели Word2Vec\n",
    "w2v_model = Word2Vec(sentences, vector_size=200, window=6, sg=1, epochs=30)  # skip-gram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "606feefc-9c70-4f2a-aead-ba9bca22e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерация эмбеддингов (среднее по k-mers)\n",
    "embeddings = {\n",
    "    sample: sum(w2v_model.wv[mer] for mer in kmers) / len(kmers) if kmers else None\n",
    "    for sample, kmers in kmers_samples.items()\n",
    "}\n",
    "\n",
    "# Подготовка данных: объединяем эмбеддинги с target\n",
    "embedding_df = pd.DataFrame.from_dict(embeddings, orient='index', dtype=float)\n",
    "embedding_df.index.name = \"sample\"\n",
    "embedding_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70d08512-1e3a-4360-94e1-8b81ae1d3e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = wide_to_long(raw_phenotypes, ['2015', '2016', '2017', '2019', '2020', '2021', '2022', '2023'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a77e5e5-65a0-41fe-9eae-ed18a68a5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_features = pd.read_csv('res_meteo.csv') # подключаем фичи с погодой\n",
    "weather_features.drop(['Unnamed: 0'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0284ba00-8f76-4a41-a7cb-c5db34dd9f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединяем с данными по урожайности\n",
    "merged_data = pd.merge(target_data, embedding_df, on=\"sample\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30606e70-72c1-40ed-b1fa-8992def003b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.year = merged_data.year.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e3cb8f1-bd8e-44ad-ba70-c474ccc39e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединяем с данными по погоде\n",
    "merged_data = pd.merge(merged_data, weather_features, on=\"year\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c226a0c2-25c1-46a0-8644-1ab18460e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на признаки и целевую переменную\n",
    "X = merged_data.drop(columns=[\"sample\", \"year\", \"yield\"])\n",
    "y = merged_data[\"yield\"]\n",
    "\n",
    "# Разделение на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89a1063-684d-45b0-b404-ad1c8888784d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-24 11:28:20,722] A new study created in memory with name: no-name-25f77a16-8b05-416e-aa36-0a52522d476b\n",
      "[I 2024-11-24 11:28:23,642] Trial 0 finished with value: 15.03968543977089 and parameters: {'learning_rate': 0.0024339015645837687, 'depth': 5, 'subsample': 0.6952686998445793, 'colsample_bylevel': 0.944742534372284, 'min_data_in_leaf': 35}. Best is trial 0 with value: 15.03968543977089.\n",
      "[I 2024-11-24 11:28:24,223] Trial 1 finished with value: 16.09352367083085 and parameters: {'learning_rate': 0.0996272375146593, 'depth': 2, 'subsample': 0.6297373378410382, 'colsample_bylevel': 0.30147257225587065, 'min_data_in_leaf': 54}. Best is trial 0 with value: 15.03968543977089.\n"
     ]
    }
   ],
   "source": [
    "# проводим отбор гиперпараметров\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": 1000,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.1, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**params, silent=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "    return rmse\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cb5f8-57d8-46a7-9dc5-7191ef278c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для упрощения работы с ноутбуком выведу параметры отдельно\n",
    "best_params = {'learning_rate': 0.0024339015645837687, 'depth': 5, 'subsample': 0.6952686998445793, 'colsample_bylevel': 0.944742534372284, 'min_data_in_leaf': 35}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9838544a-1eb0-4507-9d62-b691392f45d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Вес обратно пропорционален частоте - попробовали использовать взвешивание таргетов, но это не дало значимого прироста\n",
    "# target_counts = y_train.value_counts(normalize=True)\n",
    "# weights = y_train.map(lambda x: 1 / target_counts[x])  \n",
    "\n",
    "# обучение модели CatBoost\n",
    "catboost_model = CatBoostRegressor(\n",
    "    **best_params, \n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "catboost_model.fit(X_train,\n",
    "                   y_train,\n",
    "                   # sample_weight=weights,\n",
    "                   eval_set=(X_test, y_test),\n",
    "                   verbose=100)\n",
    "\n",
    "# предсказания и оценка\n",
    "y_pred_cb = catboost_model.predict(X_test)\n",
    "mse_cb = mean_squared_error(y_test, y_pred_cb)\n",
    "r2_cb = r2_score(y_test, y_pred_cb)\n",
    "\n",
    "print(\"CatBoost Mean Squared Error (MSE):\", mse_cb)\n",
    "print(\"CatBoost R^2 Score:\", r2_cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d4917c-9d03-4487-8408-1e8eabd92470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# посмотрим на FI\n",
    "def plot_feature_importance(importance, names, model_type):\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(10,))\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')\n",
    "\n",
    "plot_feature_importance(catboost_model.get_feature_importance(),X_train.columns,'CATBOOST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6639edf-1186-4bb7-adc6-1e961fb9ad77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
